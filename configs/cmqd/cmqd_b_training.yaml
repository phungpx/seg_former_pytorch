data:
  train:
    module: torch.utils.data
    class: DataLoader
    DataLoader:
      dataset:
        module: flame.core.data.field_dataset
        class: FieldDataset
        FieldDataset:
          dirnames:
            - '''/extdata/ocr/quann7/projects/ekyc/dataset/08082022/CCCD_front_chip/train'''
          classes:
            BACKGROUND: [[0, 0, 0], 0, False, False]  # color, class_id, reduce_height, reduce_width
            HEADING: [[175, 153, 144], 1, True, False]
            V_ID: [[75, 25, 230], 2, True, False]
            V_NAME: [[48, 130, 245], 3, True, False]
            V_SEX: [[0, 101, 255], 4, True, False]
            V_MR: [[100, 150, 255], 5, True, False]
            V_PRO: [[25, 225, 225], 6, True, False]
            DATE_1: [[75, 180, 60], 7, True, False]
            DATE_2: [[180, 215, 255], 8, True, False]
            DATE_3: [[240, 240, 70], 9, True, False]
            V_TL: [[100, 0, 100], 10, True, False]
            FIGURE: [[255, 190, 230], 11, False, False]
            LOGO: [[70, 70, 70], 12, False, False]
          reduce_ratios: (0.25, 0.25)
          image_size: (512, 512)
          image_extents: ['''.jpg''', '''.png''', '''.jpeg''', '''.JPG''', '''.PNG''', '''.JPEG''']
          label_extent: '''.json'''
          transforms:
            - iaa.Add(value=(-100, 100), per_channel=True)
            - iaa.GaussianBlur(sigma=(0, 1))
            - iaa.MotionBlur()
            - iaa.Affine(rotate=(0, 360), shear=(-20, 20), fit_output=True)
            - iaa.PerspectiveTransform(scale=(0, 0.1))
            - iaa.Crop(percent=(0, 0.1))
            - iaa.Pad(percent=(0, 0.1))
            - iaa.JpegCompression(compression=(0, 30))
            - iaa.Rot90(k=[0, 1, 2, 3], keep_size=False)
            - iaa.Fliplr(p=0.5)
            - iaa.Flipud(p=0.5)
            - iaa.Grayscale(alpha=(0.0, 1.0))
            - iaa.ChangeColorTemperature()
            - iaa.Clouds()
            - iaa.Dropout()
      batch_size: 16
      shuffle: True
      pin_memory: True
      num_workers: 12
      drop_last: False

  train_eval:
    module: torch.utils.data
    class: DataLoader
    DataLoader:
      dataset:
        module: flame.core.data.field_dataset
        class: FieldDataset
        FieldDataset:
          dirnames:
            - '''/extdata/ocr/quann7/projects/ekyc/dataset/08082022/CCCD_front_chip/train'''
          classes:
            BACKGROUND: [[0, 0, 0], 0, False, False]  # color, class_id, reduce_height, reduce_width
            HEADING: [[175, 153, 144], 1, True, False]
            V_ID: [[75, 25, 230], 2, True, False]
            V_NAME: [[48, 130, 245], 3, True, False]
            V_SEX: [[0, 101, 255], 4, True, False]
            V_MR: [[100, 150, 255], 5, True, False]
            V_PRO: [[25, 225, 225], 6, True, False]
            DATE_1: [[75, 180, 60], 7, True, False]
            DATE_2: [[180, 215, 255], 8, True, False]
            DATE_3: [[240, 240, 70], 9, True, False]
            V_TL: [[100, 0, 100], 10, True, False]
            FIGURE: [[255, 190, 230], 11, False, False]
            LOGO: [[70, 70, 70], 12, False, False]
          reduce_ratios: (0.25, 0.25)
          image_size: (512, 512)
          image_extents: ['''.jpg''', '''.png''', '''.jpeg''', '''.JPG''', '''.PNG''', '''.JPEG''']
          label_extent: '''.json'''
      batch_size: 16
      shuffle: False
      pin_memory: True
      num_workers: 12
      drop_last: False

  valid:
    module: torch.utils.data
    class: DataLoader
    DataLoader:
      dataset:
        module: flame.core.data.field_dataset
        class: FieldDataset
        FieldDataset:
          dirnames:
            - '''/extdata/ocr/quann7/projects/ekyc/dataset/08082022/CCCD_front_chip/valid'''
          classes:
            BACKGROUND: [[0, 0, 0], 0, False, False]  # color, class_id, reduce_height, reduce_width
            HEADING: [[175, 153, 144], 1, True, False]
            V_ID: [[75, 25, 230], 2, True, False]
            V_NAME: [[48, 130, 245], 3, True, False]
            V_SEX: [[0, 101, 255], 4, True, False]
            V_MR: [[100, 150, 255], 5, True, False]
            V_PRO: [[25, 225, 225], 6, True, False]
            DATE_1: [[75, 180, 60], 7, True, False]
            DATE_2: [[180, 215, 255], 8, True, False]
            DATE_3: [[240, 240, 70], 9, True, False]
            V_TL: [[100, 0, 100], 10, True, False]
            FIGURE: [[255, 190, 230], 11, False, False]
            LOGO: [[70, 70, 70], 12, False, False]
          reduce_ratios: (0.25, 0.25)
          image_size: (512, 512)
          image_extents: ['''.jpg''', '''.png''', '''.jpeg''', '''.JPG''', '''.PNG''', '''.JPEG''']
          label_extent: '''.json'''
      batch_size: 16
      shuffle: False
      pin_memory: True
      num_workers: 12
      drop_last: False

loss:
  module: flame.core.loss.OHEM_cross_entropy
  class: OHEMCrossEntropy
  OHEMCrossEntropy:
    ignore_label: 255
    weight: None
    thresh: 0.7
    output_transform: 'lambda x: (x[0], x[1])'

model:
  module: flame.core.model.encoder_decoder
  class: Model
  Model:
    backbone:
      module: flame.core.model.mix_transformer
      class: mit_b0
    decode_head:
      module: flame.core.model.segformer_head
      class: SegFormerHead
      SegFormerHead:
        # type: '''SegFormerHead'''
        feature_strides: [4, 8, 16, 32]
        in_channels: [32, 64, 160, 256]
        in_index: [0, 1, 2, 3]
        # channels: 128
        num_classes: 13
        # norm_cfg: norm_cfg
        align_corners: False
        decoder_params: 
          embed_dim: 256
        dropout_ratio: 0.1
    pretrained: '''checkpoints/segformer.b0.512x512.ade.160k.pth'''
    device: '''cuda'''

optim:
  module: torch.optim
  class: AdamW
  AdamW:
    params: config['model'].parameters()
    lr: 0.01
    weight_decay: 0.1

train_evaluator:
  module: flame.handlers.metric_evaluator
  class: MetricEvaluator
  MetricEvaluator:
    dataset: config['data']['train_eval']
    device: '''cuda'''

valid_evaluator:
  module: flame.handlers.metric_evaluator
  class: MetricEvaluator
  MetricEvaluator:
    dataset: config['data']['valid']
    device: '''cuda'''

metrics:
  module: flame.handlers.metric_evaluator
  class: Metrics
  Metrics:
    metrics:
      OHEM_ce_loss:
        module: flame.core.metric.loss
        class: Loss
        Loss:
          loss_fn: config['loss']
          output_transform: 'lambda x: (x[0], x[1])'
      Dices:
        module: ignite.metrics
        class: DiceCoefficient
        DiceCoefficient:
          cm:
            module: ignite.metrics.confusion_matrix
            class: ConfusionMatrix
            ConfusionMatrix:
              num_classes: 13
              average: None
              output_transform: 'lambda x: (x[0], x[1])'
              device: '''cuda'''
          ignore_index: 0  # background
      IoU:
        module: ignite.metrics
        class: IoU
        IoU:
          cm:
            module: ignite.metrics.confusion_matrix
            class: ConfusionMatrix
            ConfusionMatrix:
              num_classes: 13
              average: None
              output_transform: 'lambda x: (x[0], x[1])'
              device: '''cuda'''
          ignore_index: 0  # background
      mIoU:
        module: ignite.metrics.metrics_lambda
        class: MetricsLambda
        MetricsLambda:
          f: 'lambda IoUs: IoUs.mean()'
          IoUs:
            module: ignite.metrics
            class: IoU
            IoU:
              cm:
                module: ignite.metrics.confusion_matrix
                class: ConfusionMatrix
                ConfusionMatrix:
                  num_classes: 13
                  average: None
                  output_transform: 'lambda x: (x[0], x[1])'
                  device: '''cuda'''
              ignore_index: 0  # background
      mDice:
        module: ignite.metrics.metrics_lambda
        class: MetricsLambda
        MetricsLambda:
          f: 'lambda Dices: Dices.mean()'
          Dices:
            module: ignite.metrics
            class: DiceCoefficient
            DiceCoefficient:
              cm:
                module: ignite.metrics.confusion_matrix
                class: ConfusionMatrix
                ConfusionMatrix:
                  num_classes: 13
                  average: None
                  output_transform: 'lambda x: (x[0], x[1])'
                  device: '''cuda'''
              ignore_index: 0  # background
    attach_to:
      train_evaluator: '''train'''
      valid_evaluator: '''valid'''

# predictor:
#   module: flame.handlers.region_predictor
#   class: RegionPredictor
#   RegionPredictor:
#     evaluator_name: '''valid_evaluator'''
#     output_dir: '''checkpoint/CCCD_front_chip/valid'''
#     output_img_ext: '''.*g'''
#     output_mask_ext: '''.png'''
#     classes:
#       # color, class_idx, area_threshold
#       BACKGROUND: [[0, 0, 0], 0, 0.]
#       HEADING: [[175, 153, 144], 1, 0.]
#       HEADING_VI: [[175, 153, 144], 1, 0.]
#       V_ID: [[75, 25, 230], 2, 0.]
#       # V_NAME1: [[128, 0, 0], 3, 0.]
#       V_NAME2: [[48, 130, 245], 3, 0.]
#       V_BD: [[128, 128, 0], 4, 0.]
#       V_SEX: [[0, 101, 255], 5, 0.]
#       V_NAT: [[100, 150, 255], 6, 0.]
#       V_BP1: [[25, 225, 225], 7, 0.]
#       V_BP2: [[75, 180, 60], 8, 0.]
#       V_A1: [[180, 215, 255], 9, 0.]
#       V_A2: [[240, 240, 70], 10, 0.]
#       V_TL: [[100, 0, 100], 11, 0.]
#       FIGURE: [[255, 190, 230], 12, 0.]
#       QR_CODE: [[70, 70, 70], 13, 0.]
#       QR: [[70, 70, 70], 13, 0.]
#     output_transform: 'lambda x: (torch.nn.Softmax(dim=1)(x[0]).round(), x[-1])'

writer:
  module: flame.handlers.tensorboard
  class: TensorBoard
  TensorBoard:
    logdir: '''checkpoint/CCCD_front_chip/'''

logger:
  module: flame.handlers.logger
  class: Logger
  Logger:
    logdir: '''checkpoint/CCCD_front_chip/'''
    logname: '''CCCD_front_chip'''

screenlogger:
  module: flame.handlers.screenlogger
  class: ScreenLogger
  ScreenLogger:
    classes:
      - '''BACKGROUND'''
      - '''HEADING'''
      - '''HEADING_VI'''
      - '''V_ID'''
      # - '''V_NAME1'''
      - '''V_NAME2'''
      - '''V_BD'''
      - '''V_SEX'''
      - '''V_NAT'''
      - '''V_BP1'''
      - '''V_BP2'''
      - '''V_A1'''
      - '''V_A2'''
      - '''V_TL'''
      - '''FIGURE'''
      - '''QR_CODE'''
      - '''QR'''
    eval_names:
      - '''train'''
      - '''valid'''

history:
  module: flame.handlers.checkpoint
  class: History

checkpoint_loader:
  module: flame.handlers.checkpoint
  class: CheckpointLoader
  CheckpointLoader:
    checkpoint_path: ''''''
    mode: '''train'''
    device: '''cuda'''

terminate_on_nan:
  module: flame.handlers.terminate_on_nan
  class: TerminateOnNan

lr_scheduler:
  module: flame.handlers.lr_scheduler
  class: LRScheduler
  LRScheduler:
    score_name: '''OHEM_ce_loss'''
    evaluator_name: '''valid_evaluator'''
    scheduler:
      module: flame.handlers.lr_schedulers
      class: WarmupPolyLR
      WarmupPolyLR:
        optimizer: config['optim']
        data_loader: config['data']['train']
        max_epochs: config['engine']['Trainer']['max_epochs']
        power: 0.9
        warmup_scale: 10
        warmup_ratio: 0.1
        warmup: '''exp'''
        last_epoch: -1

# early_stopping:
#   module: flame.handlers.early_stopping
#   class: EarlyStopping
#   EarlyStopping:
#     score_name: '''OHEM_ce_loss'''
#     evaluator_name: '''valid_evaluator'''
#     mode: '''min'''
#     patience: 20

best_saver:
  module: flame.handlers.checkpoint
  class: BestSaver
  BestSaver:
    dirname: '''checkpoint/CCCD_front_chip/'''
    score_name: '''OHEM_ce_loss'''
    evaluator_name: '''valid_evaluator'''
    mode: '''min'''
    n_saved: 1

backup_saver:
  module: flame.handlers.checkpoint
  class: BackupSaver
  BackupSaver:
    modules:
      - '''model'''
      - '''optim'''
      - '''backup_saver'''
      - '''best_saver'''
      - '''history'''
      - '''lr_scheduler'''
      # - '''early_stopping'''
    dirname: '''checkpoint/CCCD_front_chip/'''
    save_interval: 1
    n_saved: 1

engine:
  module: flame.core.engine.engine
  class: Trainer
  Trainer:
    dataset: config['data']['train']
    device: '''cuda'''
    max_epochs: 10000

extralibs:
  iaa: imgaug.augmenters
  torch: torch
